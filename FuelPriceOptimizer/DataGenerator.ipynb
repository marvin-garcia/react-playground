{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare files and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "stations_file = \"/mnt/c/Users/magar/source/repos/react-playground/FuelPriceOptimizer/FuelPriceOptimizer.Server/Data/Zones.json\"\n",
    "zone_summary_path = \"/mnt/c/Users/magar/source/repos/react-playground/FuelPriceOptimizer/FuelPriceOptimizer.Server/Data/ZoneSummary\"\n",
    "station_summary_path = \"/mnt/c/Users/magar/source/repos/react-playground/FuelPriceOptimizer/FuelPriceOptimizer.Server/Data/StationSummary\"\n",
    "summary_files = \"/mnt/c/Users/magar/source/repos/react-playground/FuelPriceOptimizer/FuelPriceOptimizer.Server/Data/ReportFiles.json\"\n",
    "\n",
    "start_date = '2023-12-16'\n",
    "end_date = '2024-01-02'\n",
    "report_guid = str(uuid.uuid4())\n",
    "\n",
    "def generate_guid():\n",
    "    return str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding geocoordinates to stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321%20Makaala%20Street,%20Hilo,%20HI,%20USA\n",
      "68-1845%20Waikoloa%20Road,%20Waikoloa,%20HI,%20USA\n",
      "74-5035%20Queen%20Kaahumanu%20Hwy,%20Kailua-Kona,%20HI,%20USA\n",
      "20%20Maunaloa%20Highway,%20Kaunakakai,%20HI,%20USA\n",
      "4454%20Nuhou%20Street,%20Lihue,%20HI,%20USA\n",
      "4411%20Rice%20Street,%20Lihue,%20HI,%20USA\n",
      "994%20Kuhio%20Hwy,%20Kapaa,%20HI,%20USA\n",
      "3425%20Old%20Haleakala%20Hwy,%20Makawao,%20HI,%20USA\n",
      "130%20W.%20Kamehameha%20Avenue,%20Kahului,%20HI,%20USA\n",
      "3511%20Lower%20Honoapiilani%20Road,%20Lahaina,%20HI,%20USA\n",
      "7170%20Kalanianaole%20Highway,%20Honolulu,%20HI,%20USA\n",
      "710%20Kailua%20Road,%20Kailua,%20HI,%20USA\n",
      "59-186%20Kamehameha%20Hwy,%20Sunset%20Beach,%20Hi,%20USA\n",
      "91-565%20Farrington%20Highway,%20Kapolei,%20HI,%20USA\n",
      "91-909%20Fort%20Weaver%20Road,%20Ewa%20Beach,%20HI,%20USA\n",
      "866%20Kamehameha%20Highway,%20Pearl%20City,%20HI,%20USA\n",
      "98-121%20Kamehameha%20Highway,%20Aiea,%20HI,%20USA\n",
      "777%20Kamehameha%20Highway,%20Pearl%20City,%20HI,%20USA\n",
      "4561%20Salt%20Lake%20Boulevard,%20Honolulu,%20HI,%20USA\n",
      "95-130%20Kamehameha%20Hwy,%20Mililani,%20HI,%20USA\n",
      "94-485%20Farrington%20Highway,%20Waipahu,%20HI,%20USA\n",
      "1139%20Kapiolani%20Blvd,%20Honolulu,%20HI,%20USA\n",
      "1402%20N.%20School%20Road,%20Honolulu,%20HI,%20USA\n",
      "1305%20Middle%20Street,%20Honolulu,%20HI,%20USA\n",
      "5200%20Hana%20Hwy,%20Kula,%20HI,%20USA\n",
      "9212%20Kula%20Hwy,%20Hana,%20HI,%20USA\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "def get_geocoordinates(address):\n",
    "  maps_api = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "  api_key = ''\n",
    "\n",
    "  params = {'address': address, 'key': api_key}\n",
    "  response = requests.get(maps_api, params=params)\n",
    "  data = response.json()\n",
    "\n",
    "  if data['status'] == 'OK':\n",
    "    return data['results'][0]['geometry']['location']\n",
    "  else:\n",
    "    print(address)\n",
    "    # print(data)\n",
    "    return None\n",
    "\n",
    "stations_df = pd.read_json(stations_file)\n",
    "for index, station in stations_df.iterrows():\n",
    "    address = station['streetAddress'] + ', ' + station['city'] + ', ' + station['state'] + ', USA'\n",
    "    formatted_address = str.replace(address, ' ', '%20')\n",
    "\n",
    "    location = get_geocoordinates(formatted_address)\n",
    "    if location:\n",
    "      stations_df.at[index, 'latitude'] = location['lat']\n",
    "      stations_df.at[index, 'longitude'] = location['lng']\n",
    "    else:\n",
    "      stations_df.at[index, 'latitude'] = None\n",
    "      stations_df.at[index, 'longitude'] = None\n",
    "    \n",
    "    sleep(1)\n",
    "\n",
    "stations_df.to_json(f'{stations_file}', orient='records', lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate zones summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "stations_df = pd.read_json(stations_file)\n",
    "\n",
    "# Generate a date range from 8/1/19 to present\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Iterate over unique values in the 'zone' column\n",
    "for station in stations_df['zone'].unique():\n",
    "    # Create an empty DataFrame for summary\n",
    "    summary_df = pd.DataFrame()\n",
    "\n",
    "    # Generate random values for each day\n",
    "    random_data = {\n",
    "        \"avgTransferPrice\": 2.0 + np.random.uniform(0, 1, len(date_range)),\n",
    "        \"avgDtwPrice\": 3.0 + np.random.uniform(0, 1, len(date_range)),\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame for the random data\n",
    "    random_df = pd.DataFrame(random_data, index=date_range)\n",
    "\n",
    "    # Add 'date' column with the date value\n",
    "    random_df['date'] = date_range\n",
    "\n",
    "    # Add 'zone' column with the current zone value\n",
    "    random_df['zone'] = station\n",
    "\n",
    "    # Concatenate with the summary DataFrame\n",
    "    summary_df = pd.concat([summary_df, random_df])\n",
    "\n",
    "    summary_df.to_json(f'{zone_summary_path}/{station}.json', orient='records', date_format='iso', lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate stations summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "stations_df = pd.read_json(stations_file)\n",
    "\n",
    "# Generate a date range from 8/1/19 to present\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Iterate over unique values in the 'zone' column\n",
    "for station in stations_df['stationNumber'].unique():\n",
    "    # Create an empty DataFrame for summary\n",
    "    summary_df = pd.DataFrame()\n",
    "\n",
    "    # Generate random values for each day\n",
    "    random_data = {\n",
    "        \"volume\": np.random.randint(2000.0, 2500.0, len(date_range)),\n",
    "        \"rolling7DayVolume\": np.random.randint(11000.0, 18000.0, len(date_range)),\n",
    "        \"weekToWeekChangeVolume\": np.random.randint(800.0, 2500.0, len(date_range)),\n",
    "        \"changePercentage\": np.random.randint(-8.0, 8.0, len(date_range)),\n",
    "        \"margin\": np.random.randint(3000.0, 5500.0, len(date_range)),\n",
    "        \"rum\": 1.30 + np.random.uniform(0, 0.59, len(date_range)),\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame for the random data\n",
    "    random_df = pd.DataFrame(random_data, index=date_range)\n",
    "\n",
    "    # Add 'date' column with the date value\n",
    "    random_df['date'] = date_range\n",
    "\n",
    "    # Add 'stationNumber' column with the current zone value\n",
    "    random_df['stationNumber'] = station\n",
    "\n",
    "    # Concatenate with the summary DataFrame\n",
    "    summary_df = pd.concat([summary_df, random_df])\n",
    "\n",
    "    summary_df.to_json(f'{station_summary_path}/{station}.json', orient='records', date_format='iso', lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate report files list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   guid                           fileName  \\\n",
      "0  087b5c54-3eef-4c14-a8fd-1d747d2dc9a3  Wholesome RUM report V12023-12-18   \n",
      "1  087b5c54-3eef-4c14-a8fd-1d747d2dc9a3  Wholesome RUM report V12023-12-25   \n",
      "2  087b5c54-3eef-4c14-a8fd-1d747d2dc9a3  Wholesome RUM report V12024-01-01   \n",
      "\n",
      "   uploadDate                                            fileUrl  \n",
      "0  2023-12-18  https://msaidata.blob.core.windows.net/gasrepo...  \n",
      "1  2023-12-25  https://msaidata.blob.core.windows.net/gasrepo...  \n",
      "2  2024-01-01  https://msaidata.blob.core.windows.net/gasrepo...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate a date range from 8/1/19 to present, including only Mondays\n",
    "mondays = pd.date_range(start=start_date, end=end_date, freq='W-MON')\n",
    "\n",
    "# Create a DataFrame for summary_files_df\n",
    "summary_files_df = pd.DataFrame({\n",
    "    'guid': [report_guid for _ in range(len(mondays))],\n",
    "    'fileName': ['Wholesome RUM report V1' + date.strftime('%Y-%m-%d') for date in mondays],\n",
    "    'uploadDate': [date.strftime('%Y-%m-%d') for date in mondays],\n",
    "    \"fileUrl\": \"https://msaidata.blob.core.windows.net/gasreports/Wholesale%20RUM%20Report%20V2%2001.02.24.xlsm?sp=r&st=2024-01-15T18:23:29Z&se=2024-07-01T01:23:29Z&spr=https&sv=2022-11-02&sr=b&sig=N7ixD3iW1IqmuqEXR47Wb2BlzuMKrEfCfV1nAOLi4Ig%3D\",\n",
    "})\n",
    "\n",
    "# Print or use summary_files_df as needed\n",
    "print(summary_files_df)\n",
    "summary_files_df.to_json(summary_files, orient='records', date_format='iso', lines=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
